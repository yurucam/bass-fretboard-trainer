// ë¸Œë¼ìš°ì €ê°€ Safariì¸ì§€ í™•ì¸ (ë” ì •í™•í•œ ê°ì§€)
function isSafari(): boolean {
  const userAgent = navigator.userAgent.toLowerCase();

  // SafariëŠ” 'safari'ë¥¼ í¬í•¨í•˜ì§€ë§Œ 'chrome'ì´ë‚˜ 'chromium'ì„ í¬í•¨í•˜ì§€ ì•ŠìŒ
  // WebKit ê¸°ë°˜ì´ì§€ë§Œ Chrome/Edgeê°€ ì•„ë‹Œ ê²½ìš°
  return (
    userAgent.includes("safari") &&
    !userAgent.includes("chrome") &&
    !userAgent.includes("chromium") &&
    !userAgent.includes("edg") && // Edge
    !userAgent.includes("opr") && // Opera
    !userAgent.includes("firefox")
  );
}

// WebKit AudioContext íƒ€ì… ì •ì˜
declare global {
  interface Window {
    webkitAudioContext?: typeof AudioContext;
  }
}

// YIN ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ìŒ ê°ì§€ í´ë˜ìŠ¤
export class AudioPitchDetector {
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private microphone: MediaStreamAudioSourceNode | null = null;
  private timeDataArray: Float32Array | null = null;
  private animationId: number | null = null;
  private isSafariBrowser: boolean;

  constructor() {
    this.isSafariBrowser = isSafari();
  }

  // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
  async initialize(): Promise<void> {
    try {
      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
      this.audioContext = new (window.AudioContext ||
        window.webkitAudioContext)();
      console.log(
        "ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„±ë¨, ìƒ˜í”Œë§ ë ˆì´íŠ¸:",
        this.audioContext.sampleRate
      );

      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒíƒœ í™•ì¸ ë° ì¬ê°œ
      if (this.audioContext.state !== "running") {
        await this.audioContext.resume();
        console.log("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¬ê°œë¨");
      }

      // ì˜¤ë””ì˜¤ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ì„¤ì •
      const constraints: MediaStreamConstraints = {
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
        },
      };

      console.log("ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìš”ì²­ ì¤‘...");
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      console.log("ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ íšë“ ì„±ê³µ");

      // ë§ˆì´í¬ ì†ŒìŠ¤ ìƒì„±
      this.microphone = this.audioContext.createMediaStreamSource(stream);
      console.log("ë§ˆì´í¬ ì†ŒìŠ¤ ìƒì„±ë¨");

      // ì£¼íŒŒìˆ˜ ë¶„ì„ì„ ìœ„í•œ ì„¤ì •
      this.analyser = this.audioContext.createAnalyser();

      // Safariì—ì„œëŠ” ë” ì‘ì€ FFT í¬ê¸° ì‚¬ìš© (ì„±ëŠ¥ ë¬¸ì œ ë°©ì§€)
      this.analyser.fftSize = this.isSafariBrowser ? 8192 : 16384;
      this.analyser.smoothingTimeConstant = this.isSafariBrowser ? 0.9 : 0.85;

      // ì‹œê°„ ë„ë©”ì¸ ë°ì´í„°ìš© ë°°ì—´ (ìŒ ê°ì§€ìš©)
      this.timeDataArray = new Float32Array(this.analyser.fftSize);

      const frequencyResolution =
        this.audioContext.sampleRate / this.analyser.fftSize;
      console.log(
        "ë¶„ì„ê¸° ìƒì„±ë¨, FFT í¬ê¸°:",
        this.analyser.fftSize,
        "ì£¼íŒŒìˆ˜ í•´ìƒë„:",
        frequencyResolution.toFixed(3),
        "Hz",
        "Safari ë¸Œë¼ìš°ì €:",
        this.isSafariBrowser ? "ì˜ˆ" : "ì•„ë‹ˆì˜¤"
      );

      // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì—°ê²°
      this.microphone.connect(this.analyser);
      console.log("ì˜¤ë””ì˜¤ ì—°ê²° ì™„ë£Œ");
    } catch (error) {
      console.error("ì˜¤ë””ì˜¤ ì´ˆê¸°í™” ì˜¤ë¥˜:", error);
      throw error;
    }
  }

  // YIN ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ìŒ ê°ì§€
  detectPitch(): number | null {
    if (!this.analyser || !this.audioContext || !this.timeDataArray) {
      return null;
    }

    try {
      // ì‹œê°„ ë„ë©”ì¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
      this.analyser.getFloatTimeDomainData(this.timeDataArray);

      // ì‹ í˜¸ ê°•ë„ í™•ì¸ (ì¹¨ë¬µ ê°ì§€)
      let signalSum = 0;
      for (let i = 0; i < this.timeDataArray.length; i++) {
        signalSum += Math.abs(this.timeDataArray[i]);
      }

      const signalAverage = signalSum / this.timeDataArray.length;

      // ì‹ í˜¸ê°€ ë„ˆë¬´ ì•½í•˜ë©´ ë¬´ì‹œ (ì„ê³„ê°’ì„ ë”ìš± ë‚®ê²Œ ì„¤ì •)
      // Safariì—ì„œëŠ” ë” ë‚®ì€ ì„ê³„ê°’ ì‚¬ìš©
      const minSignalThreshold = this.isSafariBrowser ? 0.000001 : 0.000005;
      if (signalAverage < minSignalThreshold) {
        return null;
      }

      // ì…ë ¥ ì‹ í˜¸ ì •ê·œí™” - ë” ì •í™•í•œ ìƒê´€ê´€ê³„ ê³„ì‚°ì„ ìœ„í•´
      const normalizedSignal = new Float32Array(this.timeDataArray.length);
      for (let i = 0; i < this.timeDataArray.length; i++) {
        normalizedSignal[i] = this.timeDataArray[i] / signalAverage;
      }

      const bufferSize = normalizedSignal.length;
      const sampleRate = this.audioContext.sampleRate;

      // 5í˜„ ë² ì´ìŠ¤ Bí˜„(30.87Hz)ì„ ìœ„í•œ í™•ì¥ëœ ì£¼íŒŒìˆ˜ ë²”ìœ„
      const minPeriod = Math.floor(sampleRate / 500); // ê³ ìŒì—­ (500Hz)
      const maxPeriod = Math.ceil(sampleRate / 20); // ì €ìŒì—­ í™•ì¥ (20Hz, Bí˜„ ì•ˆì • ê°ì§€)

      // YIN ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
      const yinBuffer = new Float32Array(maxPeriod);

      // YIN ì•Œê³ ë¦¬ì¦˜ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„: ìê¸° ì°¨ì´ í•¨ìˆ˜
      for (let tau = 0; tau < maxPeriod; tau++) {
        yinBuffer[tau] = 0;

        // ì´ˆê¸° ìƒ˜í”Œì„ ì ë‹¹íˆ ê±´ë„ˆë›°ì–´ ê³„ì‚°
        const startSample = Math.floor(bufferSize * 0.1);

        for (let i = startSample; i < bufferSize - tau; i++) {
          const delta = normalizedSignal[i] - normalizedSignal[i + tau];
          yinBuffer[tau] += delta * delta;
        }
      }

      // ëˆ„ì  í‰ê·  ì •ê·œí™”
      yinBuffer[0] = 1;
      let runningSum = yinBuffer[0];
      for (let tau = 1; tau < maxPeriod; tau++) {
        runningSum += yinBuffer[tau];
        yinBuffer[tau] *= tau / runningSum;
      }

      // ê¸°ë³¸ìŒ ìš°ì„  ê°ì§€ë¥¼ ìœ„í•œ ê°œì„ ëœ ì•Œê³ ë¦¬ì¦˜ (ë°°ìŒ ì–µì œ)
      let tau = 0;
      let bestTau = 0;
      let bestValue = 1.0;
      const baseThreshold = this.isSafariBrowser ? 0.03 : 0.05;

      // ëª¨ë“  ì£¼ê¸°ì—ì„œ ìµœì ê°’ ì°¾ê¸° (ê¸°ë³¸ìŒ ìš°ì„ )
      for (tau = minPeriod; tau < maxPeriod; tau++) {
        const frequency = sampleRate / tau;

        // ì €ì£¼íŒŒìˆ˜(ê¸°ë³¸ìŒ)ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬
        let weightedValue = yinBuffer[tau];
        if (frequency < 100) {
          // ì €ì£¼íŒŒìˆ˜ì¼ìˆ˜ë¡ ë” ë‚®ì€ ê°’ìœ¼ë¡œ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„ ì¦ê°€)
          weightedValue *= frequency < 50 ? 0.7 : 0.85;
        }

        // ë°°ìŒ ì–µì œ: ì´ë¯¸ ì°¾ì€ ê¸°ë³¸ìŒì˜ ë°°ìˆ˜ ì£¼íŒŒìˆ˜ëŠ” í˜ë„í‹°
        if (bestTau > 0) {
          const bestFreq = sampleRate / bestTau;
          const ratio = frequency / bestFreq;
          // 2ë°°ìŒ, 3ë°°ìŒ ë“±ì— í˜ë„í‹° ì ìš©
          if (Math.abs(ratio - Math.round(ratio)) < 0.1 && ratio > 1.5) {
            weightedValue *= 1.5; // ë°°ìŒì— í˜ë„í‹°
          }
        }

        const adaptiveThreshold =
          frequency < 50 ? baseThreshold * 0.6 : baseThreshold;

        if (weightedValue < adaptiveThreshold && weightedValue < bestValue) {
          bestTau = tau;
          bestValue = weightedValue;
        }
      }

      tau = bestTau;
      if (tau === 0 || bestValue >= 0.5) {
        return null;
      }

      // ìœ íš¨í•œ ì£¼ê¸°ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
      if (tau === maxPeriod || yinBuffer[tau] >= 0.5) {
        return null;
      }

      // ë³´ê°„ì„ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ ì£¼ê¸° ì¶”ì •
      let betterTau: number;
      if (tau > 0 && tau < maxPeriod - 1) {
        const s0 = yinBuffer[tau - 1];
        const s1 = yinBuffer[tau];
        const s2 = yinBuffer[tau + 1];

        // í¬ë¬¼ì„  ë³´ê°„ì„ ì‚¬ìš©í•´ ìµœì†Œê°’ ìœ„ì¹˜ë¥¼ ë” ì •í™•í•˜ê²Œ ì¶”ì •
        const adjustment = (s2 - s0) / (2 * (2 * s1 - s2 - s0));

        if (Math.abs(adjustment) < 1) {
          betterTau = tau + adjustment;
        } else {
          betterTau = tau;
        }
      } else {
        betterTau = tau;
      }

      // ì£¼íŒŒìˆ˜ ê³„ì‚°
      const fundamentalFrequency = sampleRate / betterTau;

      // 5í˜„ ë² ì´ìŠ¤ Bí˜„ì„ ìœ„í•œ í™•ì¥ëœ ì£¼íŒŒìˆ˜ ë²”ìœ„ (20Hz ~ 500Hz)
      // B0(30.87Hz)ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ê°ì§€í•˜ê¸° ìœ„í•´ í•˜í•œì„ ì„ 20Hzë¡œ í™•ì¥
      if (fundamentalFrequency < 20 || fundamentalFrequency > 500) {
        return null;
      }

      // ë°°ìŒ ì–µì œ: ê°ì§€ëœ ì£¼íŒŒìˆ˜ê°€ ë°°ìŒì¼ ê°€ëŠ¥ì„± ê²€ì‚¬
      if (fundamentalFrequency > 80) {
        // ì ˆë°˜ ì£¼íŒŒìˆ˜(ê¸°ë³¸ìŒ í›„ë³´)ì—ì„œ ë” ê°•í•œ ì‹ í˜¸ê°€ ìˆëŠ”ì§€ í™•ì¸
        const halfFreqPeriod = Math.round(betterTau * 2);
        if (
          halfFreqPeriod < maxPeriod &&
          yinBuffer[halfFreqPeriod] < yinBuffer[Math.floor(betterTau)] * 0.8
        ) {
          const halfFrequency = sampleRate / halfFreqPeriod;
          if (halfFrequency >= 20 && halfFrequency <= 100) {
            console.log(
              `ğŸ”„ ë°°ìŒ ì–µì œ: ${fundamentalFrequency.toFixed(
                2
              )}Hz â†’ ${halfFrequency.toFixed(2)}Hz (ê¸°ë³¸ìŒ)`
            );
            return halfFrequency;
          }
        }
      }

      // Bí˜„ ì£¼ë³€ ì£¼íŒŒìˆ˜ ë¡œê¹… (ë””ë²„ê¹…ìš©)
      if (fundamentalFrequency >= 25 && fundamentalFrequency <= 40) {
        console.log(
          `ğŸµ ì €ì£¼íŒŒìˆ˜ ê°ì§€ (Bí˜„ í›„ë³´): ${fundamentalFrequency.toFixed(2)}Hz`
        );
      }

      return fundamentalFrequency;
    } catch (error) {
      console.error("ë² ì´ìŠ¤ ìŒ ê°ì§€ ì˜¤ë¥˜:", error);
      return null;
    }
  }

  // ì—°ì† ìŒ ê°ì§€ ì‹œì‘
  startDetection(callback: (frequency: number | null) => void): void {
    const detect = () => {
      const frequency = this.detectPitch();
      callback(frequency);
      this.animationId = requestAnimationFrame(detect);
    };

    detect();
  }

  // ìŒ ê°ì§€ ì¤‘ì§€
  stopDetection(): void {
    if (this.animationId) {
      cancelAnimationFrame(this.animationId);
      this.animationId = null;
    }
  }

  // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  async cleanup(): Promise<void> {
    this.stopDetection();

    if (this.microphone) {
      this.microphone.disconnect();
      this.microphone = null;
      console.log("ë§ˆì´í¬ ì—°ê²° í•´ì œë¨");
    }

    if (this.analyser) {
      this.analyser = null;
      console.log("ë¶„ì„ê¸° í•´ì œë¨");
    }

    if (this.audioContext) {
      try {
        await this.audioContext.close();
        console.log("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ í•´ì œë¨");
      } catch (error) {
        console.warn("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ í•´ì œ ì¤‘ ì˜¤ë¥˜:", error);
      }
      this.audioContext = null;
    }

    this.timeDataArray = null;
  }

  // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒíƒœ í™•ì¸
  get isInitialized(): boolean {
    return this.audioContext !== null && this.analyser !== null;
  }

  // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒíƒœ ë°˜í™˜
  get audioContextState(): AudioContextState | null {
    return this.audioContext?.state || null;
  }
}
